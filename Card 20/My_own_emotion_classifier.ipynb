{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AH7CI48W0z5W"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "8MvmnsDj4Gxb",
    "outputId": "deb72051-fa66-4940-e1b6-7a4dcee808af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 14:57:05.215737: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-27 14:57:05.224981: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-27 14:57:05.236192: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-27 14:57:05.239519: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-27 14:57:05.247893: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-27 14:57:05.903116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.17.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Input\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 360257508406719424\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2278096896\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8477313936919110500\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727459826.291097    9349 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727459826.293080    9349 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727459826.294184    9349 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727459826.382525    9349 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727459826.383711    9349 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727459826.384800    9349 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-27 14:57:06.385822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /device:GPU:0 with 2172 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "I0000 00:00:1727459826.386917    9349 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727459826.388079    9349 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727459826.389074    9349 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "'''\n",
    "gpus = tensorflow.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try: \n",
    "        tensorflow.config.set_logical_device_configuration(gpus[0], [tensorflow.config.LogicalDeviceConfiguration(memory_limit=3900)])\n",
    "        logical_gpus = tensorflow.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Phyisical GPUs, \", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "'''\n",
    "\n",
    "gpus = tensorflow.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tensorflow.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('./fer2013/fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "image_size = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28711 files belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727459826.927596    9349 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727459826.928825    9349 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727459826.929819    9349 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727459826.931217    9349 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727459826.932234    9349 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-27 14:57:06.933232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2172 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "training_data = image_dataset_from_directory('./fer2013/train/', labels='inferred', label_mode='categorical', batch_size=batch_size, image_size=(image_size, image_size), shuffle=True, color_mode='grayscale')\n",
    "training_data = training_data.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3589 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_data = image_dataset_from_directory('./fer2013/validation/', labels='inferred', label_mode='categorical', batch_size=batch_size, image_size=(image_size, image_size), shuffle=True, color_mode='grayscale')\n",
    "validation_data = validation_data.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "a2HSNMiUGUEK"
   },
   "outputs": [],
   "source": [
    "emotions = [\"Angry\", \"Disgusted\", \"Afraid\", \"Happy\", \"Neutral\", \"Sad\", \"Surprised\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3t1-0jcYG6oc"
   },
   "outputs": [],
   "source": [
    "training_data_normalized = training_data.map(lambda x, y: (x/255, y))\n",
    "validation_data_normalized = validation_data.map(lambda x, y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "e6MisZF9ETG_",
    "outputId": "ef1525db-8c51-4d2e-e6ea-d7b2ae455d2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 48, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvP0lEQVR4nO3deawl5Xnn8aeqzn7u1rfp2w0NNG6zGBisaUNsAmbACyHEEHeUyJokxngykz+syIosZbEVxWA5ixLbY8t2lESOAsRRlESIkNjBy4wDCfEgwCy2WbtZGug29HK773ruWeudP9q8guD39xz3bUKW70fKH+nnvnWq6lSd5xzzPE9lIYRgAACYWf5a7wAA4N8OkgIAICIpAAAikgIAICIpAAAikgIAICIpAAAikgIAICIpAAAikgL+3dizZ49lWWaf/OQnj9s277jjDsuyzO64447jts1Xw4vHfuONN77Wu4L/4EgKeFXdeOONlmWZfetb33qtd+VV86UvfckuvfRSm5ubs1arZdu3b7f3vOc99tWvfvW13jXgh0ZSANbhk5/8pP3kT/6kZVlmH/nIR+zTn/60/fRP/7Tt3r3b/vIv//K13j3gh1Z5rXcA+PdqOBzaxz/+cbv88svt61//+iviBw4ceE32C1gPfingNdfv9+2jH/2onX/++TY9PW3tdtsuueQSu/3225NrPv3pT9u2bdus2WzapZdeag899NAr/uaxxx6zn/mZn7HZ2VlrNBp2wQUX2N/93d+5+9PpdOyxxx6zQ4cOyb87dOiQLS0t2cUXX/wD43Nzc8d0jAsLC/b+97/fpqenbWZmxq699lpbWFhw9xs4HkgKeM0tLS3Zn/zJn9hll11mv/d7v2fXX3+9HTx40K644gp78MEHX/H3f/Znf2af/exn7Zd+6ZfsIx/5iD300EP29re/3fbv3x//5uGHH7YLL7zQHn30Ufvwhz9sn/rUp6zdbtvOnTvtb/7mb+T+3HPPPXb22Wfb5z//efl3c3Nz1mw27Utf+pIdPnz4uBxjCMHe/e532xe/+EV773vfa7/1W79le/futWuvvVZuHzhuAvAquuGGG4KZhXvvvTf5N8PhMPR6vZf925EjR8LmzZvDL/zCL8R/e/rpp4OZhWazGfbu3Rv//e677w5mFj70oQ/Ff3vHO94RzjvvvNDtduO/lWUZLrroonDGGWfEf7v99tuDmYXbb7/9Ff923XXXucf30Y9+NJhZaLfb4corrwy//du/He67775jPsZbb701mFn4/d///ZetveSSS4KZhRtuuMHdJ2A9+KWA11xRFFar1czMrCxLO3z4sA2HQ7vgggvs/vvvf8Xf79y507Zu3Rr//ze/+c32lre8xW677TYzMzt8+LD9wz/8g73nPe+x5eVlO3TokB06dMjm5+ftiiuusN27d9u+ffuS+3PZZZdZCMGuv/56d98/9rGP2V/8xV/Yjh077Gtf+5r9xm/8hp1//vn2pje9yR599NEf+hhvu+02q1Qq9oEPfOBlaz/4wQ+OcSaB9SMp4N+Em266yd74xjdao9GwjRs32qZNm+zv//7vbXFx8RV/e8YZZ7zi384880zbs2ePmZk98cQTFkKw3/zN37RNmza97P+uu+46s+P8H4F/9md/1u688047cuSIff3rX7ef+7mfswceeMCuvvpq63a7P9QxPvPMM3biiSfaxMTEy17jrLPOOm77CyhUH+E19+d//uf2/ve/33bu3Gm/+qu/anNzc1YUhf3u7/6uPfnkkz/09sqyNDOzX/mVX7ErrrjiB/7N6aefvu79/pempqbs8ssvt8svv9yq1arddNNNdvfdd9ull1563I8ReLWQFPCau/nmm2379u12yy23WJZl8d9f/Fb/L+3evfsV/7Zr1y477bTTzMxs+/btZmZWrVbtne9856u238oFF1xgN910kz3//PNmP8Qxbtu2zb7xjW/YysrKy34tPP744/+Ke4//zPifj/CaK4rC7PuVNy+6++677a677vqBf3/rrbe+7L8J3HPPPXb33XfblVdeafb9qqDLLrvM/viP/zh+KL/UwYMH5f6MW5La6XSS+/iVr3zF7CX/s8+4x/gTP/ETNhwO7Q//8A/jv41GI/vc5z4n9wU4XvilgH8Vf/qnf/oDxz788i//sl111VV2yy232E/91E/Zu971Lnv66aftj/7oj+ycc86xlZWVV6w5/fTT7a1vfat94AMfsF6vZ5/5zGds48aN9mu/9mvxb/7gD/7A3vrWt9p5551nv/iLv2jbt2+3/fv321133WV79+61b3/728l9veeee+xtb3ubXXfddfI/Nnc6HbvooovswgsvtB//8R+3U045xRYWFuzWW2+1O++803bu3Gk7duwwMxv7GK+++mq7+OKL7cMf/rDt2bPHzjnnHLvlllt+4H9bAV4Vr3X5E/5je7EkNfV/zz33XCjLMvzO7/xO2LZtW6jX62HHjh3hy1/+crj22mvDtm3b4rZeLEn9xCc+ET71qU+FU045JdTr9XDJJZeEb3/726947SeffDK8733vC1u2bAnVajVs3bo1XHXVVeHmm2+Of7OektTBYBC+8IUvhJ07d8Z9b7VaYceOHeETn/jEy0pQxz3GEEKYn58P11xzTZiamgrT09PhmmuuCQ888AAlqfhXkYWX/p4FAPynxn9TAABEJAUAQERSAABEJAUAQERSAABEJAUAQDR289oXHr9ExpfLRjK2paIbb27cd5GMr37+ZBmfP7tIxtZOHci11flj798bbu3J+MyGVRmf/d/tZKxy18NybT6RXmtmZqWuNA5ra+lgtSrXZoXzXaIizmnmrM0zHZ+ZkuHhCRPJWDYYybVlLX0debKRc74r+rizYSnjw8n0e1Ks6eOqLOvrNFvtJmOhnb6vzcyyjt52OdVMr+0P5dp8WVyjZrb/nSfJ+P/40JeTsR9pPiXXLoxaMq40cv2Zoz4rzczaWV/Gq1n6vBWmr8OLTtPHbfxSAAC8FEkBABCRFAAAEUkBABCRFAAAEUkBABCRFAAA0dhF+qo29mg8XSs9cnLPCQ1dz39gs1PjLUpzixVdez5q6bre6lK6bj6v6try9g0zetv3fDcZy1q6TjqspWvLzcys1PtmhTgvA11nbZV07bmZmY3Sr53V9SUXJnX/RXDWK4Opmoyr68jMLFe9BM7aYVvv92BCX+OVTvq1ywm97dzpz8iK9PuZr+g+hNBwelq64nPD+Uo6mk33nJiZbf7GK5+q91I3hKuSsa2//kW5drZ45cOdXkr1GrTN6V/KOzLeDfqczmTp+3Mp1OXacfBLAQAQkRQAABFJAQAQkRQAABFJAQAQkRQAANHY9X2FU6/XEGVSKmZm1hnqEiyv3K8Q1Zmjpi7NzIIe1ZyN0nmz8R1dNjrxtQdlPIxEqaAabW1mIeiTktV0+aUqO828sdxDXZ4sy12dsdzmHJdl+v0qa+n3yxtfXTpfkcqKM9ZbGNX12mFDxyuiajvzxqQ75yzU0h8DYdo5Z8648WJVXGdO2XTplbtO6BHUm//vvmTs10+7Rq697ZpPyPgLlt731VKXhXqjtSdzXW4+X6Y/dzY65a7j4JcCACAiKQAAIpICACAiKQAAIpICACAiKQAAIpICACAau09h5NTzb6ykR82Ogs49qwNd1zuY1K+d99Ox6qKuow46bI2D6diWbx7R21Z9CGaWi36AckmP7s1qTr2/M/46a6bHJYeeOKFjyCrissqdWn+vD8EZnT1spd9Qt17fuRbUro9Ef8RY23amlXfm0sddXdN9CsO2cw+IXW/u19dCf1pfh7VCnDRvuvuaPimhqo9ruCU9un77X+t793+++b0y/pkz/ioZG+Xr+67ddh5TUGbp96Qbjn20/Iv4pQAAiEgKAICIpAAAiEgKAICIpAAAiEgKAICIpAAAiMYuavVmgCuTuX42gMsZsd89If0HmW4VMKck2OqLoph69zN6217N/Up6SH5WOPna6YEwr1Y6pI8r9HVtej45obedHft3jdDSPSveMxGyYfpaGLXW10tg4u10WnGsVPX6ZlY6d2J3Y3p9z+kh8m7dxuH0tbA2p5/L4TxmxQbt9IEN2vqkVTv6pBRdp9FBqHX0Nb72xRNlfPVjTp+Qem3T9+7AuZg2FenP04OjdP/RuPilAACISAoAgIikAACISAoAgIikAACISAoAgIikAACIxu5T2Fjo+f4Hh1PJ2Ek1Pbs8c4qdWwd0fHVbul45G+ga7qKn4xP70vXMXj1/VtM13qrXIIycGmznuQRej0Top4vX/f326sNFfKhrtLOBjhcdXXRf1tPNBupZC2ZmTrm/+8wEuW2nByI472chLrV++tYzM7NMt35YfzJ9XLVFvdYb3x+K9IFXV/R93ZvS57u+rNdnZTpeXdQ7vvG+eRm//ul3J2OffX36WQtmZt8bTcp4y2ks6Ys+htmiK9eOg18KAICIpAAAiEgKAICIpAAAiEgKAICIpAAAiMYuSa06M6hnRclqw1kbnFpAr1Qw76f/IBvpxZVVHa/e81gyVoqSNzMzG+i53EGUpGailG8c5ZouTcvbrXRw4JR9eqW4lfRlldWdUcwdvd8hF/s9xohq+dpOpe1QTCX2Skrzgb5WvNHZilfuOmzr11b3V3/aee2qs23xtbNxwPlO6ryVy6fpeOv59PYrq3rEdHOfvnfnbz45Hfx1vV/eZ6mnECX8hfecgTHwSwEAEJEUAAARSQEAEJEUAAARSQEAEJEUAAARSQEAEI1dHV2occhmVhO1t6XTaLDU17N985Guvc3FeOzBnK65n368KuNlp5OMZXW936HXk3FVzx8GuhfAk7ecev4VPQpdKWY36D8QY7tDcOqoq84lWdHfY4pe+jota/oaHjX0tlUPhKrHNzOrdvRxDxv6HumractOf8Wo7vQSrKMlJpvT13i5mn4/O6/XvQDm9BhV5/W10p9Jx1a36LXDlm7Q2PhIup/mrxcvkGvfN3OPjB8s9edKO0uft/qxt+lE/FIAAEQkBQBARFIAAEQkBQBARFIAAEQkBQBARFIAAERj9ynM5LoeeTWk+xS2VfT88EVntvnmQ3r9sCkKrbs678397S4ZH4mae++ZB1mjIeNhKOq0c73tvOH0SDjPcshq+rkGctvOsxqyWrr3Q/VmmJlZ13lWw1BfC4V4v4Yt55z2nX4Y1S/jlNx7fQi5M2K/fiT92qtb9dps6BSvi8MKFX1ORiv6/czq6SYKr2Ulc/pKhic58eX0vg2b+nOhvU/HK930tm964Efl2ut+7BEZLwe6h6gq3s5J53NjHPxSAABEJAUAQERSAABEJAUAQERSAABEJAUAQDR2SWo10+Vfk5YeUT1SNW9mFpzR2l75WJhM1wO2duvSy9GheRlXpaFhpOsI3bLQXJS7ipiZWdnVJcJ5U5fDqnpAb7/NuRbk+qoz53lCjzIPE7p8uWykL+lKV79fI2dEu5qPHcRYbTOzrHTuAefrWaiIa8Wp7QxVHc/E6PnRjFMC3Naj6U3c215JqvOxYcH0OQ+N9LU2mNJrV71tV9LXaXWv3vEjo/Q4fhvjm3pDlF33gnN/jYFfCgCAiKQAAIhICgCAiKQAAIhICgCAiKQAAIhICgCAaOw+hU6p/7Qv8kuj1DX1J88uyPhyuy3jm/4pXTPc2q/rqMu3/lcZrx5YTsZGu56Ua3NndHbZTY+gzup6NHaWeUXeWtkRtdLe+F2nhyJT/RsDZzS20yMRSqcOW+xaEPXdZmMclzrlTo9Dpafj/bbTl6LaN5w+n1Do1y7ViGrnOgulfu1KNX0ttBrOteC89uqavkf6QZ00fY0PZvV1tij6HCpr+pzc25uW8XNqR2RcqTr9FePglwIAICIpAAAikgIAICIpAAAikgIAICIpAAAikgIAIBq7T+GF0ZSMb6uka2udUfO2oa7nixcPp3sFzMyyR0W/QK7z3vD8s2T8qZ/fnIyd8n8m5Vr75wdlOJ9Mry+XnWOu6udEhJ7uDckqY7/1x1UY6frvrKdr1/MVXV8equn4qKmPufQuVFU27329ctpK8qH38ADxPIV1jtAP9fQGsp4+36XTpzBspWPLI93HUxTOteL0MeSV9Prg9fkMnWtBrJc9JWb2SG+rjF/a1J+H+0fpe7vl9RiNgV8KAICIpAAAiEgKAICIpAAAiEgKAICIpAAAiMauS/yrQ2+W8f8194/JWDvXJVb3fvf1Mn52f1HvXCM9QrdcWZVL8zsfkPGJM380GXvi53VZ6OnZDhk38drFjB6vW66lx26bmWWZfmtVaWhWON8VnDJfK9JlcVmrqdc2dZliqOrjysQI62JNj+X2boeinz7u/qQ+JyM95dktK81FpW4mJpWPEzdRVpoNnLHczjjysitKJJ3LaLTO8fAm3i+reNt24mpEu1OmOwi6bLSeOTWtli5J7Qb9ZuvGgqP4pQAAiEgKAICIpAAAiEgKAICIpAAAiEgKAICIpAAAiMbuU/jm09tl/LyJfclYtf24XDvxlN6NlTN0zX5trp2MDRtOTfBX7pXxub/dlYz1Z/TY7b1v08d12r3pmnxvxLSn7A9kPK+JWmjRZ2Bmlom+EDMzE2O5s5oz8tvpQwgNXcMdKunvOVnpjFoe6nNe6aTjo/o6xm6PQe175tTFe70G+dqxfzcsnLVB9AqUbaeBwuslcMZ6Z730a1dW9TkZNfVrl001llsutXsXTpPxlZmHZXxajMcehHXOUeeXAgDgpUgKAICIpAAAiEgKAICIpAAAiEgKAICIpAAAiMbuU6jfn+4FMDP73Mo7krEvzFws1zb0Iw+stqjn4C+fkq6bHzmjyZuTkzJeLi4nY7OP6F6A7kZdR51vmEnGRocOy7Xm1CPLPgQzy5riuQbO8xSyqnNS19EDYV6fgvMsh7Ka3n6oOc88qHrPkUiHip6ua/f6GAYtp25erPfq4j3qWQ7B+9ro9EgU4jkQeV+/16XTp+A8lkD3OTjPgciGznEti2eGOO0VD+/fov9AtzG86vilAACISAoAgIikAACISAoAgIikAACISAoAgIikAACIxu5TKHo6PvVIuja9uqJfprqqa+6HTV2Q3J9I1xRv+Sdd718up/sQzMxy0cfQeuqIXFtb1L0d8rkDXq9AU2/bO64sT58z2cMwDtFLUE6knyFhZlY6z0vwXzt9XKO6vo7KwuslSB/XqOasbet4f0rHS3FavHr9UHWeDSDiXr1+WXN6CVTLyprTC+C9tnOpZL11NnAIRVfF9Ot2lvQ9cFtns4zv6p6YjG2o6KavD8roUfxSAABEJAUAQERSAABEJAUAQERSAABEJAUAQDR2SWplzRkNLEryejO6RKv9/EjGl0/Ru7n4hvT62soGuXbj87MybmX6uEcbWnqtM0I39NVcYZ2v5Vozy6enZDybSpfaBq8ctqdHhqv1WVevzWpjX5I/+LVD+qR7I6ZHTX3cw0Y63tugN97Tl6H1Z3RZtonNV1ad0s2GvhDzmfS1JE7n0fiq834N0+cs9J3x1c4pyfVEfX3/OddCpj+SLBflsl75fjGva2k//vC7ZLz/yHQ6tlHv+AffoPfN+KUAAHgpkgIAICIpAAAikgIAICIpAAAikgIAICIpAACi4zY6eyAmOVfW9NpM9AKYmbX369rbI+ema4YPvkPv+Myuk2U8X0vX1e99+4Rcu/UOPcY2LC4lY1mjLteqsds2xvjrUBXrS10gHprOvqlegWZNLs26uvg8VPWcaHUtVTpO8Xmmi9fzvjiuXO+XNzo7d8Y8h1PTN9Fw5DVg6O9+5SAdr7d1P4w4JWZmlh1IXysh14uz0jku57ULcU4zp8fB7ZEQ7TaZs1+t550+oL0zer14SxqH1tfnY/xSAAC8FEkBABCRFAAAEUkBABCRFAAAEUkBABCRFAAA0dhFrf0pZ2a7KD8vus6zGOo6NxVdXTR80j+l923+nIZc25/R8/2LZvoUjbxWggPpPgQzs1CI2vaqrue3ga4ft9wbGC/idf3apfPMg0z0KYyaepZ8sar7SrKB7jVQr52v6HNWfUHHs1H6Omw7vRvTs/rZG72N+rws7k+v72zW91d5clfGVb1/r6P3y1M20+esuqB7O6or+hr27j/Va1B4t4/Tx1BbED0r+rDcnq/6kr7GuxvEC+jWqLHwSwEAEJEUAAARSQEAEJEUAAARSQEAEJEUAADR+uesfp8aJTt0xgbXlnT9V2ezLourrqZrzyodudSWT9GnYNM9K8nYhsedMdBrTu1ZU5TLDvU5ySYnZTx4o7eFsqHPiTe+elRJf9fwxqSXDadk9YhTcydOeTZw6gw9ufgOJUphzcyqzy/IeOWIfr/aT6Rjw416TPrSqbose3lb+v7sbnLGqFd1PBNjuc2b+O1cwoVTaSvLStf52irulbPmI32tyJJTMyvFLVJdceZ2j4FfCgCAiKQAAIhICgCAiKQAAIhICgCAiKQAAIhICgCA6Lj1KRRr6fpYr0/B60NoHtKFv0GMia44tcyrJ+p92yRiU085TRCqrt3Mwlp657KWHrUc6s5IY6duPrTShdZer0BZ08c1aKcvq3yo9ysb6rr3vKevhXzx2GcHB2dkuBXp4w6iN8PMLHNGNWc95w+W0v0y1Rf0qOWNj+m6943T6Z6X+bfMybXLp+mPkGE7/X4Xa/re8+7dzOkHUCOswzq/DqvPtMqqvsaLvo73J/V5USPBVWxc/FIAAEQkBQBARFIAAEQkBQBARFIAAEQkBQBARFIAAERj9ylkzgzwUEnX1qp6YRujZlj1IZiZNV5I16bX5qbXte3lM6aSsalHjuhtrzg186KXIBM18WZm1hMPsDBdU29On4J3TvpT+rLpTaff8JHTClDp6uts2NbPkZh4Il2ona04fSWO/txEMtbdqHs7OnP6/VDPIzEz27A7fR1Xv7NHL86ca+HZfcnYxnl9jU+ds03GD5+TfpZDb4NcarnzOBLvK63qYxg6n3zBi4tbpOLc9oOm3nHvGTDKqO48KGIM/FIAAEQkBQBARFIAAEQkBQBARFIAAEQkBQBARFIAAERj9yl49a9DMf7fq9utL+gh4K3H9uvX3vNsMjZbvkGuPXLejIyPquK4h3qOvatI1/MHZ75+5sz+DxXdHJKtimH1E04zgVMKPUq3QFhvWi/uOT0SK84zKka19Ps5/aDTDDDS7+ewmT6n3hx7L97Z7JyX2WYydlLvFP3a9z2mX1yd865uFqg9e0jGp5ubk7EjFec6c3j9T6N0i4TbGzWqO89EKMU5c+6PYfqtNDOzxhF9sRSD9L55PRDj4JcCACAiKQAAIpICACAiKQAAIpICACAiKQAAorFLUisdXaKlZsl6Y2hHDV3DVTrje+Xa7+hyvA1PiFpaMyvfeHoylq2uybXeCOqska6ZCx09Pzfr6/JKL27N9GuPGrrWL2T6uNRYYe9a6J6gy/FGk7psdNBOv0DrgB6jXrn/CRlvr6XLM1d2nCzXLr1Ohm3U1Mc9+930SS3mV+Rapxr2VaXuAa8UfdhyPhfc8dbqQtRr85F+7UJU6taW9MYbC04p+zresErmHNgY+KUAAIhICgCAiKQAAIhICgCAiKQAAIhICgCAiKQAAIjG7lPwVFfT9bHemNpKRxfmBmd8b1YRh5HpFy/XdK9B8fhz6f1Sr2tm5tTzW5muV84aYv60mVnQ9chhONTrJ9L9GdUlPba7rOtzmg/S8cwp0fb6GJobnd6Q2fQ5P/T8pFx70h49Rr08vJDer689KNeefntVxocXnCnjuuZeXwv5RFvG5Rh2Md7dzCyI68jMLBum7+2G035Urnp9CjpeWUu/djZ07p9Cb7u6mr6/vP4kL15dEGPtzWw4mf5sqKytc5w/vxQAAC9FUgAARCQFAEBEUgAARCQFAEBEUgAARCQFAEA0dp+C98yDTJTF5yNdE9x8dlnGy4Gum8/q6brd0NM9Drl4psHRDYgeCtFncHTHnHNW1bXrr6ZsJGq4RczMn0VfDNJ/kDlz6j31qu6/mG2nn0Px1Jt078eGXXMy3nw4/YyKsJ7ryMxqT+yX8cGpm5Kx+Yu26JfOdLy9P31Oe9O6T8F7pkEhHuvh9Se1nlnV217Qz5EYPrM3Gctr+t7Lpqd0XPQRhXZTrg1VfU6zNf15p055NqBPAQBwHJEUAAARSQEAEJEUAAARSQEAEJEUAADR2CWpRVfXIXY3pksNJ5/Va7MXDuoXz50SLm+EteCOmB6lS9cyZyy3VfR+mypJdcbrWl/U+o2jFCWpPV3WVvR0KWG1kz4vasS6mVllRR/30rIu91Mlq1u26lnNe65Ol32amc1ue10yNvE9fR2VdX1cK1v0tbK6NR3rz+nXzjt62wtr6fun0tH73Z/R18L0rvT6uV26pDTbs0/GncpoK84+PRlbO1mPUa8u6/srX0uf88wZZa7uPTOzzLm380Vx75beWfHxSwEAEJEUAAARSQEAEJEUAAARSQEAEJEUAAARSQEAEI1d4N865Iz+FfXls3emR9iamQ3nD8t43tS16SbqgjNnfLVb1atqip1xyOvi7LflTj4vnB4Jdc6cOuvc6WPI++nXzvVUYKst6eMeHtLjrw+I0dyT02tybWVzeuy2mdn8j9bSMW8keNXp7WjqEe/VWrouvuq8dOf5CRkPg/QGumd09X41nD6fXe1kKJ9fkktHrztZxg+dr8db52LXgnPOaqv6o7G6kr4Hqqte75PTq6NXW74i3hOnB2Ic/FIAAEQkBQBARFIAAEQkBQBARFIAAEQkBQBARFIAAERj9ylMfvNp/QdijnfZ0fXf+YSuo/Zqb4OYPx4GujA+q+u6d1XPv27quLznKTh9ClnDOS61dk3XzFcq+rXLerpPodLVa6vLet8qy/q8DIr0MypWK/q9rNX1HPv2pvT8/8FI94V4l5F6DoSZ2Vov3SPRXdbvdWXVeb9q6Z079UTdQ9QZiGeCmFlX3NvdMzfLtZVv3Cfjc/2zZHzx3A3JWPOg/lwYtPVHY1D3p9OHYIXTO1VzPpbVxdTV9+44+KUAAIhICgCAiKQAAIhICgCAiKQAAIhICgCAiKQAAIjG7lPImg0ZHz7zXDLmPQ+hXHX6GJya+6wqDsN75oHorzi68VfxmQmy/8J5HoLTxxDUOTGzTBx3qDiv7VDbzvWjGMbYuA6HqnjtXL+XjZruU8iy9LZ1tb7/2qoPwcys90IrGSt6zjMopvRJL6bSNfutqq7n39LWz0T4TnNTMjaY1NdZY+tJMr4g+hDMzDLRL1BZ1sdVer0EIi4uk6NrvY8Ur89B9Sl4z1EZA78UAAARSQEAEJEUAAARSQEAEJEUAAARSQEAEI1dklpOt2U8b6VL5mzklMRtmJbxrKoL/oYv7BeLnRpGr35MlX4O9LjjrOKNwF1HTvZKaZ3R2kEdtzOq3JMN09su+nrbWalL6iodp/xyLX3cg0KXfa4418Kwl34/J6fX9Nqhvhb6e/T4+MaR9HH1Z7xrQcer1fT9WXFKaYelvs4Gk+nXXtvgjBt/yykyvvjf9Zz13q6pZGz6gfQYdDOzxnJXxkfT6TL7UcsrUNaygVO3re7tur7Gx8EvBQBARFIAAEQkBQBARFIAAEQkBQBARFIAAEQkBQBANHafQnDq3vOJdB9DOX9YrlWjls38cbDFTLrPoVxZlWuD00Mh+wG8tSOn3l+dfa+/YqjHPJvpceNq+9lQH1fp9UCoscPOW+2p6HYAqy6l9805LBsM9Hh49RVqeSVdE29m1n5aX8ObvueM1j4hHRvoNh/3nKux3rVc9+KUwblOhZFzuudP0uds+6z+XNk9FO9JR19ImVfvL/oUyoo+J9UVfe/mi7qHQhrq92sc/FIAAEQkBQBARFIAAEQkBQBARFIAAEQkBQBARFIAAERj9ynkfaf+VdTzZ3WnZt577kBNzyfPRMFzWHJqfjMnL4Z0DXdwarSPvYLbzHp9HXfOmddrECrpGvDgnG9PNhTnTD2fYow+hGG6PNzMzHJx2grVP2Fm1WV9TuW2nbdrw+P6/gm6JN+WtqWv08xph8m6euOjUXrbnaGu129V9IGPmunPhUFb33vdk/Q1fNHsUzK+Kz8tGQvO/eXdu8VKL73W6U8qjji9U930to/G0896yNZ57xq/FAAAL0VSAABEJAUAQERSAABEJAUAQERSAABEY5ekZp10GZSZWSjT5WNZq6W33dZ1hqp80rwxt6Kk9OjideRFZ+R38MbYFuK1nf1yy12dcya37ZTr5Wq/zaxspC+r4Jzu0tltZ5KzVTvpWNF3Soi90doT6Vh9QV8Lrb26NPrgBXr+9dqJ6Z0LFf3aWUsf2DlbXkjGhk6tbC3X266dKMov903KtaeesV/GG7keQS2vNaekOzhlpdnhxWSscMbeh4Ez9t55bVmy6m17DPxSAABEJAUAQERSAABEJAUAQERSAABEJAUAQERSAABEY/cpeL0Clqfj3jhXd9vO+rKZ7lPInR6Jck33X6yvj8HpkZD1yE6tsvPSmffawdvCscvEtitdvV+juq7xFlPSj6qK9U5zR3dOn5NRLR0/9at6HHK2V9fc18/QNfuV1fR1ONika9NrLd138vqJQ8nYGU293/+8cLqMV6vpPobV/6LvvXPbSzL+rcVtMl7piDfc61/aoPtGbDn9fpcrzmjsvjNn3et/GomelSF9CgCA44ikAACISAoAgIikAACISAoAgIikAACISAoAgGjsPgWvVyCbEP0AXs18ofsUyprezVE7vW+1E2b1tp/dq/ctqLp3J6c6vQDu8xYE93kKfV2vnKmZ787zFKzqzKIX21axo3+gw5lzKannMQwm9MaHk84M/UF63yvPHpBrva6QmW+ln2lgZpaPtiRj8+eI54mY2bCl792bV9+UjJ192vNy7ZGufhZKr5e+VradOC/XPrO0QcbrhX6Wg3oUxNoF2+XalRP1NT71bPoeqT+3INfmosfBzCw4n5dZW3zWih6GcfFLAQAQkRQAABFJAQAQkRQAABFJAQAQkRQAANH4JakDXT4ZmvV0cOiUjjWc0dgNpyS1ka49G81OybX2nM6LakytZbrQMCucnKtKcZ2yNLecdaBfW423tqpTfuxcC/ng2MvivJLTzDls9ZYMdfWkhdwpIW6k4/2zTpJr8398QMazhUUZbz+3LxmbvF2P3R6cq0dMz5+XPjGPLZ0q19q0M6p5NX3vPjOv35B8TZcvl2KUuZlZtZKOH9ihr/HerN722ub0513tzDm51qtPDhVnfLyuQF43fikAACKSAgAgIikAACKSAgAgIikAACKSAgAgIikAAKLx+xS8MdDVdM29HNNsZqHi9AqsIz6Ybci19akJGR/J+nGnl8A5Z+746/Xw3q9Ret+zwjmuuq7xVipr6xvtO2zqMetFLx2rLTpnfEnfDoPJ9Dnd99/02pPy9HhqM7Pad5+R8dGh9Jjp0ZEjcm31MX3/zDROS8ZCJvqPzGzY0vFSXCrDlr5G1Vozs1rH+VwRl0p3zrnGna/LnZPS69e2OPvl3fi53rfKSnrnvN6NcfBLAQAQkRQAABFJAQAQkRQAABFJAQAQkRQAABFJAQAQjd+n4BF18aO2HgAenOcOePPFVU2xV9fe2DAj46b6FJxeACu9uPPwgPWsVc+BML1v3rMasoo+p+q8FN319SlUV/W1UBEz+GtLem1/QsebB9KxYUsutf0/ovtlGqedKeMn3JvuRSgfekyuVT0OZma1+S3JWDHQ926voc/ZsC2uM+8ycur5BxP6/ir66Q1kQ73xwnlMhOXp9SOnV8DtTxq9qh1MLn4pAAAikgIAICIpAAAikgIAICIpAAAikgIAICIpAACisfsUsm5f/0EtPfx8MKVrnV2iJtjMLBuJWmhnbdluHvNuucKx9xK4z2LwnlGhX1lvu6Fn5IfVjozn1fRllQ11vX7e0d9T8p4esq+erdGb1WsHLf3aa3Ppc+7N38+duvel1+t4yDckYydUz5VrR2193IuvT98Di85+jdq67yQXvQJen4In7zq9BqJnpa4vYVcmDruXfqvMzCx4n7pOm0Ip1ue99fc48EsBABCRFAAAEUkBABCRFAAAEUkBABCRFAAA0dglqaHvlKT2j73stKzq3JQ59ZWqHFCVq5qZDTfoktSikj5FwRmNHbzx1ZnYcaecNai15o/1liWt3shvp+A1U+sH+pyEpj6u4YQur2x9d18yVuusybXt7SfJ+MrrJpKx1TldX9mblWG3pHXxLLFf26bk2tK5NTd+J/1+ZW59pFPyXRXl4hV9HeVdfVJKZ0S1GgA/cirRVcmpOaW2uTOWu8ydzw3nWijUR/E6pvG/iF8KAICIpAAAiEgKAICIpAAAiEgKAICIpAAAiEgKAIBo/NHZzqhm66dnAxc9XTxb1pw+BafXQI3HljXzZjZs6fry6nS6Bnx0+Ihc6/UKqD6GTIyfNhujl8CLF8c+YtftWVlcSsequmA/FE6fgtPHsP/KbcnYxodW5dr84adlvH3fcjI2dfrr5NqVczfJeH9SH1dvKh1fOVW/1/UF/V53Novx1k5PiqrXPyodL72ieu8rq7Nc9UEEZ7eDnh5v1hS9HSO98dxrX3LiijuWewz8UgAARCQFAEBEUgAARCQFAEBEUgAARCQFAEBEUgAARMehqvX7RJ9CZbknlw4m9G54NcWqj8F7FkPp1etvmE7H5g/rtR71zASvz8B53oIVuv/CquK5BE6vgPushpoY4N/TPQ7Fon7pyRV9LdlZG5KhvW9PPw/BzKxy4XkyPv10ekJ/bVFN7zebvP97Mh5aDRkfbJlMxiae1w9MWN3s9EBsSN8D1WV9f2TrmN9f1vQ1qp7FcPTFne2LzXvdFWqtOZ8r6zknNs7nnTot3qNQxsAvBQBARFIAAEQkBQBARFIAAEQkBQBARFIAAETjl6R6o7NFmWK+sKJ3YkaX443qOnflw/RrlxVnjO1A14+FljdDNy2r6lLBMEiXZ4ZhusR3rNfOnHHklfRbn9X1MXvx0YFD6bVOuWt26lYdPyLGcpvZ5P9bSK8tT5NruzO6DnHf29L7Hmb0ddbcdaqMTz957HWM/Un92qv6lMoaR6+80hsTrdbnziXujuX2PpLE21k6n3zet2V1XMGr6C7WV2qryk7XWw5r/FIAALwUSQEAEJEUAAARSQEAEJEUAAARSQEAEJEUAADR+H0KTd1LEFY7yVjmjEuuHlnTrz3b1K+dpwt7vdHZqsfBzCyoEdRO74ZXkx+GXkGy2rhXDO30X/TSI6iz6fSYZjOzUNWXTbF1S3rtsu5ZsfkjMlx29ejsIEa4T3zzSbm2cebJMl7009fh4XN0T8raG7oy3nmdM6tZXCuVRb12XbXrXi+Ac4OpXoFspLedD/SLq22b0wdR6LfD7TWQr+uNr3ZmY3ufWfK8reMj5UX8UgAARCQFAEBEUgAARCQFAEBEUgAARCQFAEBEUgAARGP3KZSTulcg74heg9x5HsLhZRmvVPT64VR6vn828oqGHYUo/HV6BcLIG0Z/7Dk5U/0TYzyPIayl36/M6yWYndHbroua/fYmve3BUIbL3U/JeFZLv3bpHFfx4G4Z3zB/UjKWj06Qa1cP6j4fj6rJ72xe33x+Vc/v9Qp4z0QoqyLmfPqUVacHQmz7qPS+e3ee2u+jmxbPoHD6j7z+DC+unqcgY2PilwIAICIpAAAikgIAICIpAAAikgIAICIpAAAikgIAIBq7TyE4vQZhopWMZWveDHz9vIV8ST9voSKea1DW9SGqZzF48cx5rkBwau4zse1QHoeCY/XalXQhdrmk6/lz5zkStmE6HXMG1fe3irVmVpk6V8bD/Y+KoPOMCadvJH/ue+ngGzfKtY15/dqDtj6n3Y2i5l5fZm6fwrCVvtbc5w5414Lg1uM7O5719T2itu/2IThUL8K6nl/hP25BP8aFPgUAwPFEUgAARCQFAEBEUgAARCQFAEBEUgAARGOXpGalrrMqJ9Mlqfnyqt62GHdsZmZ9PZ83X0hvv9w0pdd6461VSWrFKUl1Sm3NxDzkUtfrBae80hutnU9NpLd9yha97fklGS9F6Wa+cVbv17Qe0b56alvGJ4Znpbe9/7BcOzp8RMaXrzwvGdt/oa4jLDpO6bNzJ2bDdK2hN946FLpOsSL2LRvpbY+aTg2kCHv77ZV2evtW1tIv7pWkuq9drqMkdb1lo+Kw1Yj1cfFLAQAQkRQAABFJAQAQkRQAABFJAQAQkRQAABFJAQAQZSGEV3dGMwDg3w1+KQAAIpICACAiKQAAIpICACAiKQAAIpICACAiKQAAIpICACAiKQAAov8PnmIi/+ohTD8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 14:57:07.829645: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "sample = training_data_normalized.take(1)\n",
    "for image_batch, labels_batch in sample:\n",
    "    print(image_batch.shape)\n",
    "    first_image = image_batch[0]\n",
    "    first_label = labels_batch[0]\n",
    "    plt.imshow((first_image.numpy() * 255).astype('uint8'))\n",
    "    plt.title(f\"Label: {emotions[np.argmax(first_label)]}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8iKENIPYKabL",
    "outputId": "4f9da33e-ee1b-4040-8720-e8e27c86dc0e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Emotion_recon_3000\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Emotion_recon_3000\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">18,876,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">37,750,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18432</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">37,750,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m2,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │     \u001b[38;5;34m4,719,616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │     \u001b[38;5;34m9,438,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m18,876,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m37,750,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18432\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m37,750,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m3,591\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115,324,679</span> (439.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m115,324,679\u001b[0m (439.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115,309,831</span> (439.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m115,309,831\u001b[0m (439.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,848</span> (58.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,848\u001b[0m (58.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_features = 256\n",
    "num_labels = 7 #len(emotions)\n",
    "epochs = 100\n",
    "width, height = image_size, image_size\n",
    "\n",
    "i = Input(shape=(width, height, 1))\n",
    "x = Conv2D(num_features, kernel_size = (3,3), activation=\"relu\", padding = 'same', kernel_regularizer = l2(0.01))(i)\n",
    "x = Conv2D(num_features, kernel_size = (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv2D(2*num_features, kernel_size = (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(2*num_features, kernel_size = (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv2D(2*2*num_features, kernel_size = (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(2*2*num_features, kernel_size = (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv2D(2*2*2*num_features, kernel_size = (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(2*2*2*num_features, kernel_size = (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(2*2*2*num_features, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(2*2*num_features, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(2*num_features, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "o = Dense(num_labels, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs = i, outputs = o, name='Emotion_recon_3000')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#model.compile(optimizer = Adam(weight_decay=None, learning_rate=0.9), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jklErRzGqBh0"
   },
   "source": [
    "num_features = 64\n",
    "num_labels = 7\n",
    "epochs = 100\n",
    "width, height = image_size, image_size\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(num_features, kernel_size=(3,3), activation='relu',\n",
    "                 input_shape=(width, height, 1), data_format = 'channels_last',\n",
    "                 kernel_regularizer = l2(0.01)))\n",
    "model.add(Conv2D(num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(2*2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(2*2*2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2*2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2*num_features, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2VOTjT1d6HBG"
   },
   "outputs": [],
   "source": [
    "model_file = 'expression_recognition_01.keras'\n",
    "model_file_json = 'expression_recognition_01.json'\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor = 0.9, patience = 6, mode = 'auto', verbose = 1, min_lr=0.0000000001)\n",
    "early_stopper = EarlyStopping(patience=15)\n",
    "checkpointer = ModelCheckpoint(model_file, verbose = 1, save_best_only = True)\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(model_file_json, 'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wCI2uaNDqcDM"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adam(learning_rate = 0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "arquivo_modelo = 'modelo_01_expressoes.keras'\n",
    "arquivo_modelo_json = 'modelo_01_expressoes.json'\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor = 0.8, patience=3, verbose = 1)\n",
    "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience = 8, verbose = 1, mode = 'auto')\n",
    "checkpointer = ModelCheckpoint(arquivo_modelo, monitor='val_loss', verbose = 1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vT9fI-Ec8D10",
    "outputId": "e5380cf7-d806-4ad2-b72c-da657a15b73b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727459831.699342    9420 service.cc:146] XLA service 0x7f76c00027d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1727459831.699360    9420 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2024-09-27 14:57:11.790607: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-27 14:57:12.184630: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-09-27 14:57:15.101017: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-09-27 14:57:15.470744: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-09-27 14:57:15.618285: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-09-27 14:57:15.846809: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-09-27 14:57:18.337982: W external/local_xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below 1.59GiB (1712842265 bytes) by rematerialization; only reduced to 1.85GiB (1987840288 bytes), down from 1.85GiB (1987840368 bytes) originally\n",
      "I0000 00:00:1727459839.804024    9420 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-09-27 14:57:29.808453: W external/local_tsl/tsl/framework/bfc_allocator.cc:482] Allocator (GPU_0_bfc) ran out of memory trying to allocate 144.00MiB (rounded to 150994944)requested by op \n",
      "2024-09-27 14:57:29.808527: I external/local_tsl/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-09-27 14:57:29.808549: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 56, Chunks in use: 56. 14.0KiB allocated for chunks. 14.0KiB in use in bin. 449B client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808566: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808584: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 17, Chunks in use: 17. 17.8KiB allocated for chunks. 17.8KiB in use in bin. 17.1KiB client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808601: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 24, Chunks in use: 24. 49.2KiB allocated for chunks. 49.2KiB in use in bin. 48.0KiB client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808618: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 24, Chunks in use: 24. 96.0KiB allocated for chunks. 96.0KiB in use in bin. 96.0KiB client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808635: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 32, Chunks in use: 32. 274.0KiB allocated for chunks. 274.0KiB in use in bin. 274.0KiB client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808650: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808665: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808679: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808692: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808705: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808740: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808755: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808773: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 7, Chunks in use: 6. 16.35MiB allocated for chunks. 13.27MiB in use in bin. 13.00MiB client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808790: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 4, Chunks in use: 4. 18.00MiB allocated for chunks. 18.00MiB in use in bin. 18.00MiB client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808809: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 6, Chunks in use: 6. 53.00MiB allocated for chunks. 53.00MiB in use in bin. 52.00MiB client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808826: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 4, Chunks in use: 4. 72.00MiB allocated for chunks. 72.00MiB in use in bin. 72.00MiB client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808845: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 4, Chunks in use: 4. 162.00MiB allocated for chunks. 162.00MiB in use in bin. 144.00MiB client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808877: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 4, Chunks in use: 4. 288.00MiB allocated for chunks. 288.00MiB in use in bin. 288.00MiB client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808896: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 5, Chunks in use: 5. 720.00MiB allocated for chunks. 720.00MiB in use in bin. 720.00MiB client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808911: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 2. 842.77MiB allocated for chunks. 842.77MiB in use in bin. 720.09MiB client-requested in use in bin.\n",
      "2024-09-27 14:57:29.808921: I external/local_tsl/tsl/framework/bfc_allocator.cc:1062] Bin for 144.00MiB was 128.00MiB, Chunk State: \n",
      "2024-09-27 14:57:29.808930: I external/local_tsl/tsl/framework/bfc_allocator.cc:1075] Next region of size 2278096896\n",
      "2024-09-27 14:57:29.808944: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626000000 of size 1280 next 1\n",
      "2024-09-27 14:57:29.808952: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626000500 of size 256 next 2\n",
      "2024-09-27 14:57:29.808959: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626000600 of size 256 next 3\n",
      "2024-09-27 14:57:29.808966: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626000700 of size 256 next 4\n",
      "2024-09-27 14:57:29.808973: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626000800 of size 256 next 5\n",
      "2024-09-27 14:57:29.808979: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626000900 of size 256 next 6\n",
      "2024-09-27 14:57:29.808986: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626000a00 of size 256 next 7\n",
      "2024-09-27 14:57:29.808993: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626000b00 of size 256 next 8\n",
      "2024-09-27 14:57:29.809000: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626000c00 of size 256 next 9\n",
      "2024-09-27 14:57:29.809006: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626000d00 of size 256 next 10\n",
      "2024-09-27 14:57:29.809013: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626000e00 of size 256 next 11\n",
      "2024-09-27 14:57:29.809020: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626000f00 of size 256 next 12\n",
      "2024-09-27 14:57:29.809027: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626001000 of size 9216 next 13\n",
      "2024-09-27 14:57:29.809041: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626003400 of size 256 next 14\n",
      "2024-09-27 14:57:29.809053: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626003500 of size 256 next 15\n",
      "2024-09-27 14:57:29.809066: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626003600 of size 256 next 16\n",
      "2024-09-27 14:57:29.809074: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626003700 of size 256 next 17\n",
      "2024-09-27 14:57:29.809081: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626003800 of size 256 next 18\n",
      "2024-09-27 14:57:29.809088: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626003900 of size 1024 next 20\n",
      "2024-09-27 14:57:29.809095: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626003d00 of size 256 next 21\n",
      "2024-09-27 14:57:29.809102: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626003e00 of size 256 next 19\n",
      "2024-09-27 14:57:29.809109: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626003f00 of size 1024 next 22\n",
      "2024-09-27 14:57:29.809117: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626004300 of size 256 next 27\n",
      "2024-09-27 14:57:29.809124: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626004400 of size 1024 next 25\n",
      "2024-09-27 14:57:29.809133: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626004800 of size 1024 next 26\n",
      "2024-09-27 14:57:29.809141: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626004c00 of size 1024 next 30\n",
      "2024-09-27 14:57:29.809148: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626005000 of size 1024 next 31\n",
      "2024-09-27 14:57:29.809156: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626005400 of size 256 next 32\n",
      "2024-09-27 14:57:29.809163: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626005500 of size 256 next 33\n",
      "2024-09-27 14:57:29.809169: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626005600 of size 256 next 34\n",
      "2024-09-27 14:57:29.809176: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626005700 of size 2048 next 35\n",
      "2024-09-27 14:57:29.809184: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626005f00 of size 2048 next 36\n",
      "2024-09-27 14:57:29.809192: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626006700 of size 2048 next 37\n",
      "2024-09-27 14:57:29.809199: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626006f00 of size 2048 next 40\n",
      "2024-09-27 14:57:29.809207: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626007700 of size 3328 next 23\n",
      "2024-09-27 14:57:29.809215: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626008400 of size 9216 next 24\n",
      "2024-09-27 14:57:29.809223: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762600a800 of size 256 next 41\n",
      "2024-09-27 14:57:29.809230: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762600a900 of size 256 next 42\n",
      "2024-09-27 14:57:29.809237: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762600aa00 of size 2048 next 43\n",
      "2024-09-27 14:57:29.809245: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762600b200 of size 2048 next 46\n",
      "2024-09-27 14:57:29.809258: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762600ba00 of size 2048 next 44\n",
      "2024-09-27 14:57:29.809271: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762600c200 of size 2048 next 45\n",
      "2024-09-27 14:57:29.809284: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762600ca00 of size 2048 next 49\n",
      "2024-09-27 14:57:29.809297: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762600d200 of size 256 next 50\n",
      "2024-09-27 14:57:29.809308: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762600d300 of size 256 next 51\n",
      "2024-09-27 14:57:29.809320: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762600d400 of size 256 next 52\n",
      "2024-09-27 14:57:29.809333: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762600d500 of size 4096 next 53\n",
      "2024-09-27 14:57:29.809347: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762600e500 of size 4096 next 54\n",
      "2024-09-27 14:57:29.809360: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762600f500 of size 4096 next 55\n",
      "2024-09-27 14:57:29.809375: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626010500 of size 4096 next 58\n",
      "2024-09-27 14:57:29.809386: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626011500 of size 4096 next 59\n",
      "2024-09-27 14:57:29.809398: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626012500 of size 256 next 60\n",
      "2024-09-27 14:57:29.809410: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626012600 of size 256 next 61\n",
      "2024-09-27 14:57:29.809424: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626012700 of size 4096 next 62\n",
      "2024-09-27 14:57:29.809436: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626013700 of size 4096 next 65\n",
      "2024-09-27 14:57:29.809450: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626014700 of size 4096 next 63\n",
      "2024-09-27 14:57:29.809465: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626015700 of size 4096 next 64\n",
      "2024-09-27 14:57:29.809477: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626016700 of size 4096 next 68\n",
      "2024-09-27 14:57:29.809491: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626017700 of size 256 next 69\n",
      "2024-09-27 14:57:29.809505: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626017800 of size 256 next 70\n",
      "2024-09-27 14:57:29.809516: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626017900 of size 256 next 71\n",
      "2024-09-27 14:57:29.809529: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626017a00 of size 8192 next 72\n",
      "2024-09-27 14:57:29.809545: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626019a00 of size 8192 next 73\n",
      "2024-09-27 14:57:29.809558: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762601ba00 of size 8192 next 74\n",
      "2024-09-27 14:57:29.809570: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762601da00 of size 8192 next 77\n",
      "2024-09-27 14:57:29.809585: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762601fa00 of size 8192 next 78\n",
      "2024-09-27 14:57:29.809598: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626021a00 of size 256 next 79\n",
      "2024-09-27 14:57:29.809608: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626021b00 of size 256 next 80\n",
      "2024-09-27 14:57:29.809619: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626021c00 of size 8192 next 81\n",
      "2024-09-27 14:57:29.809633: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626023c00 of size 8192 next 84\n",
      "2024-09-27 14:57:29.809646: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626025c00 of size 8192 next 82\n",
      "2024-09-27 14:57:29.809659: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626027c00 of size 8192 next 83\n",
      "2024-09-27 14:57:29.809674: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626029c00 of size 8192 next 87\n",
      "2024-09-27 14:57:29.809686: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762602bc00 of size 256 next 88\n",
      "2024-09-27 14:57:29.809697: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762602bd00 of size 256 next 89\n",
      "2024-09-27 14:57:29.809710: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762602be00 of size 256 next 90\n",
      "2024-09-27 14:57:29.809739: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762602bf00 of size 8192 next 91\n",
      "2024-09-27 14:57:29.809751: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762602df00 of size 256 next 94\n",
      "2024-09-27 14:57:29.809764: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762602e000 of size 256 next 92\n",
      "2024-09-27 14:57:29.809777: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762602e100 of size 256 next 93\n",
      "2024-09-27 14:57:29.809789: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762602e200 of size 4096 next 96\n",
      "2024-09-27 14:57:29.809800: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762602f200 of size 256 next 99\n",
      "2024-09-27 14:57:29.809813: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762602f300 of size 256 next 97\n",
      "2024-09-27 14:57:29.809826: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762602f400 of size 256 next 98\n",
      "2024-09-27 14:57:29.809839: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762602f500 of size 2097152 next 117\n",
      "2024-09-27 14:57:29.809852: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762622f500 of size 14336 next 119\n",
      "2024-09-27 14:57:29.809866: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626232d00 of size 9216 next 124\n",
      "2024-09-27 14:57:29.809880: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626235100 of size 9216 next 132\n",
      "2024-09-27 14:57:29.809892: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626237500 of size 9216 next 133\n",
      "2024-09-27 14:57:29.809906: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626239900 of size 1024 next 134\n",
      "2024-09-27 14:57:29.809921: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626239d00 of size 2427648 next 29\n",
      "2024-09-27 14:57:29.809937: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762648a800 of size 2359296 next 28\n",
      "2024-09-27 14:57:29.809952: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76266ca800 of size 2097152 next 106\n",
      "2024-09-27 14:57:29.809967: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268ca800 of size 2048 next 101\n",
      "2024-09-27 14:57:29.809980: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268cb000 of size 256 next 103\n",
      "2024-09-27 14:57:29.809992: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268cb100 of size 256 next 104\n",
      "2024-09-27 14:57:29.810008: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268cb200 of size 256 next 102\n",
      "2024-09-27 14:57:29.810021: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268cb300 of size 256 next 105\n",
      "2024-09-27 14:57:29.810034: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268cb400 of size 256 next 108\n",
      "2024-09-27 14:57:29.810049: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268cb500 of size 9216 next 109\n",
      "2024-09-27 14:57:29.810063: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268cd900 of size 8192 next 115\n",
      "2024-09-27 14:57:29.810076: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268cf900 of size 4096 next 116\n",
      "2024-09-27 14:57:29.810091: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268d0900 of size 2048 next 118\n",
      "2024-09-27 14:57:29.810105: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268d1100 of size 256 next 120\n",
      "2024-09-27 14:57:29.810117: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268d1200 of size 256 next 121\n",
      "2024-09-27 14:57:29.810132: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268d1300 of size 1024 next 122\n",
      "2024-09-27 14:57:29.810144: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268d1700 of size 256 next 123\n",
      "2024-09-27 14:57:29.810161: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268d1800 of size 1280 next 125\n",
      "2024-09-27 14:57:29.810175: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268d1d00 of size 256 next 126\n",
      "2024-09-27 14:57:29.810191: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268d1e00 of size 256 next 127\n",
      "2024-09-27 14:57:29.810206: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268d1f00 of size 256 next 128\n",
      "2024-09-27 14:57:29.810221: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268d2000 of size 256 next 129\n",
      "2024-09-27 14:57:29.810237: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268d2100 of size 256 next 131\n",
      "2024-09-27 14:57:29.810252: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268d2200 of size 1280 next 111\n",
      "2024-09-27 14:57:29.810268: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268d2700 of size 14336 next 112\n",
      "2024-09-27 14:57:29.810285: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76268d5f00 of size 2574592 next 39\n",
      "2024-09-27 14:57:29.810300: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626b4a800 of size 4718592 next 38\n",
      "2024-09-27 14:57:29.810317: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7626fca800 of size 9437184 next 110\n",
      "2024-09-27 14:57:29.810332: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76278ca800 of size 9437184 next 48\n",
      "2024-09-27 14:57:29.810349: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76281ca800 of size 9437184 next 47\n",
      "2024-09-27 14:57:29.810363: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7628aca800 of size 8388608 next 100\n",
      "2024-09-27 14:57:29.810379: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76292ca800 of size 4718592 next 107\n",
      "2024-09-27 14:57:29.810394: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762974a800 of size 2359296 next 135\n",
      "2024-09-27 14:57:29.810410: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762998a800 of size 1024 next 136\n",
      "2024-09-27 14:57:29.810424: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762998ac00 of size 1024 next 137\n",
      "2024-09-27 14:57:29.810440: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762998b000 of size 1024 next 138\n",
      "2024-09-27 14:57:29.810455: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762998b400 of size 1024 next 139\n",
      "2024-09-27 14:57:29.810471: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762998b800 of size 1024 next 140\n",
      "2024-09-27 14:57:29.810486: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762998bc00 of size 1024 next 141\n",
      "2024-09-27 14:57:29.810502: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762998c000 of size 2048 next 144\n",
      "2024-09-27 14:57:29.810518: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762998c800 of size 2048 next 145\n",
      "2024-09-27 14:57:29.810533: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762998d000 of size 2048 next 146\n",
      "2024-09-27 14:57:29.810550: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762998d800 of size 2048 next 147\n",
      "2024-09-27 14:57:29.810565: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762998e000 of size 2048 next 148\n",
      "2024-09-27 14:57:29.810581: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762998e800 of size 2048 next 149\n",
      "2024-09-27 14:57:29.810596: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762998f000 of size 2048 next 152\n",
      "2024-09-27 14:57:29.810612: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762998f800 of size 2048 next 153\n",
      "2024-09-27 14:57:29.810627: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7629990000 of size 2048 next 154\n",
      "2024-09-27 14:57:29.810644: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7629990800 of size 2048 next 155\n",
      "2024-09-27 14:57:29.810659: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7629991000 of size 2048 next 156\n",
      "2024-09-27 14:57:29.810674: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7629991800 of size 2048 next 157\n",
      "2024-09-27 14:57:29.810690: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7629992000 of size 4096 next 160\n",
      "2024-09-27 14:57:29.810705: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7629993000 of size 4096 next 161\n",
      "2024-09-27 14:57:29.810733: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7629994000 of size 4096 next 162\n",
      "2024-09-27 14:57:29.810748: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7629995000 of size 4096 next 163\n",
      "2024-09-27 14:57:29.810765: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7629996000 of size 4096 next 164\n",
      "2024-09-27 14:57:29.810780: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7629997000 of size 4096 next 165\n",
      "2024-09-27 14:57:29.810796: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7629998000 of size 4096 next 168\n",
      "2024-09-27 14:57:29.810811: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7629999000 of size 4096 next 169\n",
      "2024-09-27 14:57:29.810828: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762999a000 of size 4096 next 170\n",
      "2024-09-27 14:57:29.810843: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762999b000 of size 4096 next 171\n",
      "2024-09-27 14:57:29.810859: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762999c000 of size 4096 next 172\n",
      "2024-09-27 14:57:29.810874: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762999d000 of size 4096 next 173\n",
      "2024-09-27 14:57:29.810890: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762999e000 of size 8192 next 176\n",
      "2024-09-27 14:57:29.810906: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76299a0000 of size 8192 next 177\n",
      "2024-09-27 14:57:29.810921: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76299a2000 of size 8192 next 178\n",
      "2024-09-27 14:57:29.810937: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76299a4000 of size 8192 next 179\n",
      "2024-09-27 14:57:29.810952: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76299a6000 of size 8192 next 180\n",
      "2024-09-27 14:57:29.810968: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76299a8000 of size 8192 next 181\n",
      "2024-09-27 14:57:29.810984: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76299aa000 of size 8192 next 183\n",
      "2024-09-27 14:57:29.810999: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76299ac000 of size 8192 next 184\n",
      "2024-09-27 14:57:29.811016: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76299ae000 of size 8192 next 185\n",
      "2024-09-27 14:57:29.811030: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76299b0000 of size 8192 next 186\n",
      "2024-09-27 14:57:29.811047: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76299b2000 of size 8192 next 187\n",
      "2024-09-27 14:57:29.811062: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76299b4000 of size 8192 next 188\n",
      "2024-09-27 14:57:29.811078: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f76299b6000 of size 3229696 next 57\n",
      "2024-09-27 14:57:29.811094: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7629cca800 of size 18874368 next 56\n",
      "2024-09-27 14:57:29.811111: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762aeca800 of size 18874368 next 113\n",
      "2024-09-27 14:57:29.811128: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762c0ca800 of size 56623104 next 67\n",
      "2024-09-27 14:57:29.811143: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f762f6ca800 of size 37748736 next 66\n",
      "2024-09-27 14:57:29.811163: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7631aca800 of size 75497472 next 76\n",
      "2024-09-27 14:57:29.811178: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76362ca800 of size 75497472 next 75\n",
      "2024-09-27 14:57:29.811196: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f763aaca800 of size 150994944 next 114\n",
      "2024-09-27 14:57:29.811210: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7643aca800 of size 150994944 next 86\n",
      "2024-09-27 14:57:29.811225: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f764caca800 of size 150994944 next 85\n",
      "2024-09-27 14:57:29.811240: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7655aca800 of size 150994944 next 95\n",
      "2024-09-27 14:57:29.811254: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f765eaca800 of size 604077056 next 130\n",
      "2024-09-27 14:57:29.811270: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7682ae2400 of size 4718592 next 142\n",
      "2024-09-27 14:57:29.811281: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7682f62400 of size 4718592 next 143\n",
      "2024-09-27 14:57:29.811294: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76833e2400 of size 9437184 next 150\n",
      "2024-09-27 14:57:29.811307: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7683ce2400 of size 9437184 next 151\n",
      "2024-09-27 14:57:29.811320: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76845e2400 of size 18874368 next 158\n",
      "2024-09-27 14:57:29.811333: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76857e2400 of size 18874368 next 159\n",
      "2024-09-27 14:57:29.811347: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76869e2400 of size 37748736 next 166\n",
      "2024-09-27 14:57:29.811362: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f7688de2400 of size 37748736 next 167\n",
      "2024-09-27 14:57:29.811375: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f768b1e2400 of size 75497472 next 174\n",
      "2024-09-27 14:57:29.811387: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f768f9e2400 of size 75497472 next 175\n",
      "2024-09-27 14:57:29.811402: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f76941e2400 of size 150994944 next 182\n",
      "2024-09-27 14:57:29.811417: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f769d1e2400 of size 279632896 next 18446744073709551615\n",
      "2024-09-27 14:57:29.811431: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-09-27 14:57:29.811451: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 56 Chunks of size 256 totalling 14.0KiB\n",
      "2024-09-27 14:57:29.811467: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 14 Chunks of size 1024 totalling 14.0KiB\n",
      "2024-09-27 14:57:29.811482: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 1280 totalling 3.8KiB\n",
      "2024-09-27 14:57:29.811497: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 23 Chunks of size 2048 totalling 46.0KiB\n",
      "2024-09-27 14:57:29.811513: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3328 totalling 3.2KiB\n",
      "2024-09-27 14:57:29.811528: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 24 Chunks of size 4096 totalling 96.0KiB\n",
      "2024-09-27 14:57:29.811544: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 24 Chunks of size 8192 totalling 192.0KiB\n",
      "2024-09-27 14:57:29.811559: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 9216 totalling 54.0KiB\n",
      "2024-09-27 14:57:29.811574: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 14336 totalling 28.0KiB\n",
      "2024-09-27 14:57:29.811590: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 2097152 totalling 4.00MiB\n",
      "2024-09-27 14:57:29.811606: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 2359296 totalling 4.50MiB\n",
      "2024-09-27 14:57:29.811622: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2427648 totalling 2.31MiB\n",
      "2024-09-27 14:57:29.811639: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2574592 totalling 2.46MiB\n",
      "2024-09-27 14:57:29.811656: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 4718592 totalling 18.00MiB\n",
      "2024-09-27 14:57:29.811672: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 8388608 totalling 8.00MiB\n",
      "2024-09-27 14:57:29.811690: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 5 Chunks of size 9437184 totalling 45.00MiB\n",
      "2024-09-27 14:57:29.811706: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 18874368 totalling 72.00MiB\n",
      "2024-09-27 14:57:29.811731: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 37748736 totalling 108.00MiB\n",
      "2024-09-27 14:57:29.811749: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 56623104 totalling 54.00MiB\n",
      "2024-09-27 14:57:29.811765: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 75497472 totalling 288.00MiB\n",
      "2024-09-27 14:57:29.811782: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 5 Chunks of size 150994944 totalling 720.00MiB\n",
      "2024-09-27 14:57:29.811800: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 279632896 totalling 266.68MiB\n",
      "2024-09-27 14:57:29.811817: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 604077056 totalling 576.09MiB\n",
      "2024-09-27 14:57:29.811832: I external/local_tsl/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 2.12GiB\n",
      "2024-09-27 14:57:29.811848: I external/local_tsl/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 2278096896 memory_limit_: 2278096896 available bytes: 0 curr_region_allocation_bytes_: 4556193792\n",
      "2024-09-27 14:57:29.811870: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                      2278096896\n",
      "InUse:                      2274867200\n",
      "MaxInUse:                   2274867200\n",
      "NumAllocs:                         976\n",
      "MaxAllocSize:               1225676544\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-09-27 14:57:29.811903: W external/local_tsl/tsl/framework/bfc_allocator.cc:494] ***********************************************************************************************xxxxx\n",
      "2024-09-27 14:57:29.813342: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 150994944 bytes.\n",
      "BufferAssignment OOM Debugging.\n",
      "BufferAssignment stats:\n",
      "             parameter allocation:    1.29GiB\n",
      "              constant allocation:        52B\n",
      "        maybe_live_out allocation:    1.29GiB\n",
      "     preallocated temp allocation:  576.09MiB\n",
      "  preallocated temp fragmentation:         0B (0.00%)\n",
      "                 total allocation:    1.85GiB\n",
      "              total fragmentation:    16.1KiB (0.00%)\n",
      "Peak buffers:\n",
      "\tBuffer 1:\n",
      "\t\tSize: 144.00MiB\n",
      "\t\tOperator: op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Emotion_recon_3000_1/conv2d_7_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1177\n",
      "\t\tXLA Label: custom-call\n",
      "\t\tShape: f32[2048,2048,3,3]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 2:\n",
      "\t\tSize: 144.00MiB\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[3,3,2048,2048]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 3:\n",
      "\t\tSize: 144.00MiB\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[3,3,2048,2048]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 4:\n",
      "\t\tSize: 144.00MiB\n",
      "\t\tOperator: op_name=\"XLA_Args\"\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[2048,2048,3,3]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 5:\n",
      "\t\tSize: 144.00MiB\n",
      "\t\tOperator: op_type=\"AssignSubVariableOp\" op_name=\"adam/AssignSubVariableOp_30\" source_file=\"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1177\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[18432,2048]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 6:\n",
      "\t\tSize: 144.00MiB\n",
      "\t\tOperator: op_type=\"AssignSubVariableOp\" op_name=\"adam/AssignSubVariableOp_30\" source_file=\"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1177\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[18432,2048]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 7:\n",
      "\t\tSize: 144.00MiB\n",
      "\t\tOperator: op_name=\"XLA_Retvals\"\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[3,3,2048,2048]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 8:\n",
      "\t\tSize: 144.00MiB\n",
      "\t\tOperator: op_name=\"XLA_Retvals\"\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[3,3,2048,2048]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 9:\n",
      "\t\tSize: 144.00MiB\n",
      "\t\tOperator: op_type=\"AssignSubVariableOp\" op_name=\"adam/AssignSubVariableOp_30\" source_file=\"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1177\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[18432,2048]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 10:\n",
      "\t\tSize: 144.00MiB\n",
      "\t\tOperator: op_name=\"XLA_Retvals\"\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[3,3,2048,2048]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 11:\n",
      "\t\tSize: 72.00MiB\n",
      "\t\tOperator: op_name=\"XLA_Retvals\"\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[3,3,1024,2048]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 12:\n",
      "\t\tSize: 72.00MiB\n",
      "\t\tOperator: op_name=\"XLA_Retvals\"\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[3,3,1024,2048]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 13:\n",
      "\t\tSize: 72.00MiB\n",
      "\t\tOperator: op_name=\"XLA_Retvals\"\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[3,3,1024,2048]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 14:\n",
      "\t\tSize: 36.00MiB\n",
      "\t\tOperator: op_name=\"XLA_Args\"\n",
      "\t\tEntry Parameter Subshape: f32[3,3,1024,1024]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 15:\n",
      "\t\tSize: 36.00MiB\n",
      "\t\tOperator: op_name=\"XLA_Args\"\n",
      "\t\tEntry Parameter Subshape: f32[3,3,1024,1024]\n",
      "\t\t==========================\n",
      "\n",
      "\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib64/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib64/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n\n  File \"/usr/lib64/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_9349/1384525204.py\", line 1, in <module>\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nOut of memory while trying to allocate 150994944 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:    1.29GiB\n              constant allocation:        52B\n        maybe_live_out allocation:    1.29GiB\n     preallocated temp allocation:  576.09MiB\n  preallocated temp fragmentation:         0B (0.00%)\n                 total allocation:    1.85GiB\n              total fragmentation:    16.1KiB (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 144.00MiB\n\t\tOperator: op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Emotion_recon_3000_1/conv2d_7_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1177\n\t\tXLA Label: custom-call\n\t\tShape: f32[2048,2048,3,3]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 144.00MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,2048,2048]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 144.00MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,2048,2048]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 144.00MiB\n\t\tOperator: op_name=\"XLA_Args\"\n\t\tXLA Label: fusion\n\t\tShape: f32[2048,2048,3,3]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 144.00MiB\n\t\tOperator: op_type=\"AssignSubVariableOp\" op_name=\"adam/AssignSubVariableOp_30\" source_file=\"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1177\n\t\tXLA Label: fusion\n\t\tShape: f32[18432,2048]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 144.00MiB\n\t\tOperator: op_type=\"AssignSubVariableOp\" op_name=\"adam/AssignSubVariableOp_30\" source_file=\"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1177\n\t\tXLA Label: fusion\n\t\tShape: f32[18432,2048]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 144.00MiB\n\t\tOperator: op_name=\"XLA_Retvals\"\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,2048,2048]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 144.00MiB\n\t\tOperator: op_name=\"XLA_Retvals\"\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,2048,2048]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 144.00MiB\n\t\tOperator: op_type=\"AssignSubVariableOp\" op_name=\"adam/AssignSubVariableOp_30\" source_file=\"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1177\n\t\tXLA Label: fusion\n\t\tShape: f32[18432,2048]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 144.00MiB\n\t\tOperator: op_name=\"XLA_Retvals\"\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,2048,2048]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 72.00MiB\n\t\tOperator: op_name=\"XLA_Retvals\"\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,1024,2048]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 72.00MiB\n\t\tOperator: op_name=\"XLA_Retvals\"\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,1024,2048]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 72.00MiB\n\t\tOperator: op_name=\"XLA_Retvals\"\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,1024,2048]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 36.00MiB\n\t\tOperator: op_name=\"XLA_Args\"\n\t\tEntry Parameter Subshape: f32[3,3,1024,1024]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 36.00MiB\n\t\tOperator: op_name=\"XLA_Args\"\n\t\tEntry Parameter Subshape: f32[3,3,1024,1024]\n\t\t==========================\n\n\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_8310]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data_normalized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_data_normalized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mlr_reducer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib64/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib64/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n\n  File \"/usr/lib64/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_9349/1384525204.py\", line 1, in <module>\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\nOut of memory while trying to allocate 150994944 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:    1.29GiB\n              constant allocation:        52B\n        maybe_live_out allocation:    1.29GiB\n     preallocated temp allocation:  576.09MiB\n  preallocated temp fragmentation:         0B (0.00%)\n                 total allocation:    1.85GiB\n              total fragmentation:    16.1KiB (0.00%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 144.00MiB\n\t\tOperator: op_type=\"Conv2DBackpropFilter\" op_name=\"gradient_tape/Emotion_recon_3000_1/conv2d_7_1/convolution/Conv2DBackpropFilter\" source_file=\"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1177\n\t\tXLA Label: custom-call\n\t\tShape: f32[2048,2048,3,3]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 144.00MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,2048,2048]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 144.00MiB\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,2048,2048]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 144.00MiB\n\t\tOperator: op_name=\"XLA_Args\"\n\t\tXLA Label: fusion\n\t\tShape: f32[2048,2048,3,3]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 144.00MiB\n\t\tOperator: op_type=\"AssignSubVariableOp\" op_name=\"adam/AssignSubVariableOp_30\" source_file=\"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1177\n\t\tXLA Label: fusion\n\t\tShape: f32[18432,2048]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 144.00MiB\n\t\tOperator: op_type=\"AssignSubVariableOp\" op_name=\"adam/AssignSubVariableOp_30\" source_file=\"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1177\n\t\tXLA Label: fusion\n\t\tShape: f32[18432,2048]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 144.00MiB\n\t\tOperator: op_name=\"XLA_Retvals\"\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,2048,2048]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 144.00MiB\n\t\tOperator: op_name=\"XLA_Retvals\"\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,2048,2048]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 144.00MiB\n\t\tOperator: op_type=\"AssignSubVariableOp\" op_name=\"adam/AssignSubVariableOp_30\" source_file=\"/home/zanchet/dev/LAMIA/LAMIA_venv/lib64/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1177\n\t\tXLA Label: fusion\n\t\tShape: f32[18432,2048]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 144.00MiB\n\t\tOperator: op_name=\"XLA_Retvals\"\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,2048,2048]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 72.00MiB\n\t\tOperator: op_name=\"XLA_Retvals\"\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,1024,2048]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 72.00MiB\n\t\tOperator: op_name=\"XLA_Retvals\"\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,1024,2048]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 72.00MiB\n\t\tOperator: op_name=\"XLA_Retvals\"\n\t\tXLA Label: fusion\n\t\tShape: f32[3,3,1024,2048]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 36.00MiB\n\t\tOperator: op_name=\"XLA_Args\"\n\t\tEntry Parameter Subshape: f32[3,3,1024,1024]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 36.00MiB\n\t\tOperator: op_name=\"XLA_Args\"\n\t\tEntry Parameter Subshape: f32[3,3,1024,1024]\n\t\t==========================\n\n\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_8310]"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_data_normalized,\n",
    "                    epochs = epochs,\n",
    "                    steps_per_epoch = 10,\n",
    "                    validation_data = validation_data_normalized,\n",
    "                    callbacks = [lr_reducer, checkpointer],\n",
    "                    validation_steps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "bAWB9BB2_gvO",
    "outputId": "0b48acf4-4812-4301-fa5f-101f79b0ec96"
   },
   "outputs": [],
   "source": [
    "history"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
